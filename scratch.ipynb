{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ac276c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import random\n",
    "import torch\n",
    "from typing import Literal\n",
    "import torchvision\n",
    "from torchvision.datasets import ImageFolder\n",
    "from tqdm.auto import tqdm\n",
    "import wandb\n",
    "import torchmetrics\n",
    "import shutil\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b5a89ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA_DIR = Path('raw/Garbage classification/')\n",
    "DATA_DIR = Path('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c197b1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 6 artists>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dct = {}\n",
    "for cls in os.listdir(RAW_DATA_DIR):\n",
    "    images = Path(RAW_DATA_DIR / cls).glob('*')\n",
    "    # print(cls, ' has ', len(list(images)))\n",
    "    dct[cls] = len(list(images))\n",
    "\n",
    "plt.bar(dct.keys(), dct.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18095c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = os.listdir(RAW_DATA_DIR)\n",
    "train_size = 0.80\n",
    "\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "def copy_images(image_list, src_dir, dest_dir, cls, train=True):\n",
    "    os.makedirs(dest_dir, exist_ok=True)\n",
    "    os.makedirs(dest_dir / ('train' if train else 'test'), exist_ok=True)\n",
    "    os.makedirs(dest_dir / ('train' if train else 'test') / cls, exist_ok=True)\n",
    "    for img_name in image_list:\n",
    "        if train:\n",
    "            shutil.copy(src_dir / cls / img_name, dest_dir / 'train' / cls / img_name)\n",
    "        else:\n",
    "            shutil.copy(src_dir / cls / img_name, dest_dir / 'test' / cls / img_name)\n",
    "\n",
    "# for cls in classes:\n",
    "#     cls_path = RAW_DATA_DIR / cls\n",
    "#     images = os.listdir(cls_path)\n",
    "#     n_train = int(len(images) * train_size)\n",
    "#     random.shuffle(images)\n",
    "#     train_images = images[:n_train]\n",
    "#     test_images = images[n_train:]\n",
    "#     copy_images(train_images, RAW_DATA_DIR, DATA_DIR, cls, train=True)\n",
    "#     copy_images(test_images, RAW_DATA_DIR, DATA_DIR, cls, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "93e8ae4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((128, 128)),\n",
    "    torchvision.transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0a4c6259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'cardboard', 1: 'glass', 2: 'metal', 3: 'paper', 4: 'plastic', 5: 'trash'}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = ImageFolder(DATA_DIR / 'train', transform=transformers)\n",
    "test_dataset = ImageFolder(DATA_DIR / 'test', transform=transformers)\n",
    "assert train_dataset.class_to_idx == test_dataset.class_to_idx\n",
    "\n",
    "idx_to_class = {i:c for c, i in train_dataset.class_to_idx.items()}\n",
    "idx_to_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3f282316",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoaderWrapper(pl.LightningDataModule):\n",
    "    def __init__(self, \n",
    "                 train_dataset:torch.utils.data.Dataset,\n",
    "                 test_dataset:torch.utils.data.Dataset,\n",
    "                 batch_size:int=32,\n",
    "                 num_workers:int=4):\n",
    "        super().__init__()\n",
    "        self.train_dataset = train_dataset\n",
    "        self.test_dataset = test_dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    " \n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.num_workers\n",
    "        )\n",
    " \n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "622747f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, \n",
    "                 num_layers=5, # m\n",
    "                 filter_size=3, # k\n",
    "                 num_dense=128, # n\n",
    "                 conv_activation=nn.ReLU,\n",
    "                 dense_activation=nn.ReLU,\n",
    "                 in_channels=3,\n",
    "                 num_classes=6,\n",
    "                 stride=1,\n",
    "                 input_size=128,\n",
    "                 base_features=16,\n",
    "                 *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        layers = []\n",
    "        out_channels = in_channels\n",
    "        w, h = input_size, input_size\n",
    "        for i in range(num_layers):\n",
    "            out_channels = base_features * (2 ** i)\n",
    "            layers.append(\n",
    "                nn.Conv2d(\n",
    "                    in_channels=in_channels,\n",
    "                    out_channels=out_channels,\n",
    "                    kernel_size=filter_size,\n",
    "                    padding='same',\n",
    "                    stride=stride\n",
    "                )\n",
    "            )\n",
    "            layers.append(conv_activation())\n",
    "            layers.append(nn.MaxPool2d(kernel_size=2))\n",
    "            \n",
    "            w, h = w//2, h//2\n",
    "            in_channels = out_channels\n",
    "\n",
    "        self.conv = nn.Sequential(*layers)\n",
    "        nn.Flatten()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(out_channels*w*h, num_dense),\n",
    "            dense_activation(),\n",
    "            nn.Linear(num_dense, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020f7a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param at conv0: 448\n",
      "param at conv1: 4640\n",
      "param at conv2: 18496\n",
      "param at conv3: 73856\n",
      "param at conv4: 295168\n",
      "after m convs: 392160\n",
      "param after dense1: 524416\n",
      "param after dense3: 774\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "917798"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# num_filters -> m \n",
    "# kernel -> k \n",
    "# dense -> n\n",
    "# base_features = 16\n",
    "# c_in -> 3 (input channels)\n",
    "\n",
    "# --- CONV ---\n",
    "# param in a layer -> (c_in * k * k + 1) * c_out\n",
    "# c_out = c_in * (2 ** i)\n",
    "# param per layer -> (3 * k * k + 1) * (base_features * (2 ** i)) # for i == 0\n",
    "# param per layer -> ((base_features * (2 ** (i-1))) * k * k + 1) * (base_features * (2 ** i)) # for i > 0\n",
    "\n",
    "# --- DENSE ---\n",
    "# out_channels -> base_features * (2 ** (m-1)) # c_out of last conv layer\n",
    "# w_out_convs -> w_in // (2**m)\n",
    "# h_out_convs = w_out_convs\n",
    "# param in dense layer[1] -> (base_features * (2 ** (m-1)) * h_out_convs * w_out_convs + 1) * n # +1 for bias\n",
    "# dense layer[3] -> n * 6 + 6 # classes => 6\n",
    "# dense total = (base_features * (2 ** (m-1)) + 1) * n + n * 6 + 6\n",
    "\n",
    "# --- TOTAL ---\n",
    "# total params -> (3 * k * k + 1) * (base_features * (2 ** i)) + summation(((base_features * (2 ** (i-1))) * k * k + 1) * (base_features * (2 ** i)) for i=1 to m-1) + (base_features * (2 ** (m-1)) + 1) * n + n * 6 + 6\n",
    "\n",
    "def calculate_param(\n",
    "        m:int, k:int, n:int, base_features:int, c_in:int, w_in:int, h_in:int\n",
    "):\n",
    "    \"\"\"\n",
    "    - num_filters -> m (5) \n",
    "    - kernel -> k (3)\n",
    "    - dense -> n (128)\n",
    "    - base_features = 16\n",
    "    - c_in -> 3 (input channels)\n",
    "    \"\"\"\n",
    "    param_conv0 = (c_in*k*k + 1) * base_features \n",
    "    print(f\"param at conv0: {param_conv0}\")\n",
    "    param_conv_m = 0\n",
    "    for i in range(1, m):\n",
    "        param_conv_m += ((base_features * (2 ** (i-1))) * k * k + 1) * (base_features * (2 ** i))\n",
    "        print(f\"param at conv{i}: {((base_features * (2 ** (i-1))) * k * k + 1) * (base_features * (2 ** i))}\")\n",
    "\n",
    "    print(f\"after m convs: {param_conv_m}\")\n",
    "    conv_total = param_conv0 + param_conv_m\n",
    "\n",
    "    w_out_convs = w_in // (2**m)\n",
    "    h_out_convs = h_in // (2**m)\n",
    "    dense_l1 = (base_features*(2**(m-1))* w_out_convs * h_out_convs + 1) * n\n",
    "    print(f\"param after dense1: {dense_l1}\")\n",
    "    dense_l3 = 6 * n + 6\n",
    "    print(f\"param after dense3: {dense_l3}\")\n",
    "    total_params = conv_total + dense_l1 + dense_l3\n",
    "    return total_params\n",
    "\n",
    "calculate_param(m=5, k=3, n=128, base_features=16, c_in=3, w_in=128, h_in=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3a88e063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "917798"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchinfo\n",
    "m = SimpleCNN()\n",
    "torchinfo.summary(m, input_size=(32, 3, 128, 128)).total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cba8745a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "\n",
    "class ModelLightning(pl.LightningModule):\n",
    "    def __init__(self, \n",
    "                 model,\n",
    "                 idx_to_class:dict,\n",
    "                 run:wandb.Run,\n",
    "                 lr:float=1e-3,\n",
    "                 class_weights:torch.Tensor = None,\n",
    "                 *args: Any, **kwargs: Any) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.model = model\n",
    "\n",
    "        self.run = run\n",
    "        self.idx_to_class = idx_to_class\n",
    "\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)\n",
    "        self.criterion = nn.CrossEntropyLoss() if not class_weights else nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "        self.f1 = torchmetrics.F1Score('multiclass', num_classes=6,\n",
    "                                       average=None)\n",
    "        self.recall = torchmetrics.Recall('multiclass', num_classes=6, average=None)\n",
    "        self.precision = torchmetrics.Precision('multiclass', num_classes=6, average=None)\n",
    "\n",
    "        self.train_preds = []\n",
    "        self.train_targets = []\n",
    "        self.train_loss = []\n",
    "        self.val_preds = []\n",
    "        self.val_targets = []\n",
    "        self.val_loss = []\n",
    "\n",
    "    def forward(self, x) -> Any:\n",
    "        return self.model(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        yhat = self(x)\n",
    "        loss = self.criterion(yhat, y)\n",
    "\n",
    "        self.train_preds.append(yhat.detach())\n",
    "        self.train_targets.append(y)\n",
    "        self.train_loss.append(loss.item())\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        yhat = self(x)\n",
    "        self.val_preds.append(yhat.detach())\n",
    "        self.val_targets.append(y)\n",
    "        loss = self.criterion(yhat, y)\n",
    "        self.val_loss.append(loss.item())\n",
    "    \n",
    "    def on_train_epoch_end(self) -> None:\n",
    "        self._shared_logging(mode='train',\n",
    "                             preds=self.train_preds,\n",
    "                             targets=self.train_targets,\n",
    "                             losses=self.train_loss)\n",
    "    \n",
    "    def on_validation_epoch_end(self) -> None:\n",
    "        self._shared_logging(mode='val',\n",
    "                             preds=self.val_preds,\n",
    "                             targets=self.val_targets,\n",
    "                             losses=self.val_loss)\n",
    "\n",
    "    def _shared_logging(self, mode:Literal['train', 'val'], \n",
    "                        preds, targets, losses):\n",
    "        _preds = torch.cat(preds).argmax(1)\n",
    "        loss = torch.mean(torch.tensor(losses))\n",
    "        f1 = self.f1(_preds, torch.cat(targets))\n",
    "        recall = self.recall(_preds, torch.cat(targets))\n",
    "        precision = self.precision(_preds, torch.cat(targets)) \n",
    "\n",
    "        # per class\n",
    "        for i in range(6):\n",
    "            self.run.log(data={\n",
    "                f'{mode}_f1_class_{self.idx_to_class[i]}': f1[i],\n",
    "                f'{mode}_recall_class_{self.idx_to_class[i]}': recall[i],\n",
    "                f'{mode}_precision_class_{self.idx_to_class[i]}': precision[i],\n",
    "            })\n",
    "        \n",
    "        self.run.log({\n",
    "            f'{mode}_loss': loss,\n",
    "        })\n",
    "        self.log(\n",
    "            f'{mode}_loss', loss,\n",
    "            prog_bar=True, on_epoch=True\n",
    "        )\n",
    "\n",
    "        preds.clear()\n",
    "        targets.clear()\n",
    "        losses.clear()\n",
    "        self.f1.reset()\n",
    "        self.recall.reset()\n",
    "        self.precision.reset()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return self.optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4535ef35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/nevrohelios/project/garbage_clf/wandb/run-20251213_071647-rvd4sl1h</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/23f2001173-indian-institute-of-technology-madras/garbage-classification/runs/rvd4sl1h' target=\"_blank\">simple-cnn</a></strong> to <a href='https://wandb.ai/23f2001173-indian-institute-of-technology-madras/garbage-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/23f2001173-indian-institute-of-technology-madras/garbage-classification' target=\"_blank\">https://wandb.ai/23f2001173-indian-institute-of-technology-madras/garbage-classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/23f2001173-indian-institute-of-technology-madras/garbage-classification/runs/rvd4sl1h' target=\"_blank\">https://wandb.ai/23f2001173-indian-institute-of-technology-madras/garbage-classification/runs/rvd4sl1h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class CFG:\n",
    "    batch_size = 64\n",
    "    num_workers = 4\n",
    "    max_epochs = 10\n",
    "    lr = 1e-3\n",
    "    num_layers=5 # m\n",
    "    filter_size=3 # k\n",
    "    num_dense=128 # n\n",
    "    conv_activation=nn.ReLU\n",
    "    dense_activation=nn.ReLU\n",
    "    in_channels=3\n",
    "    num_classes=6\n",
    "    stride=1\n",
    "    input_size=128\n",
    "    num_classes = 6\n",
    "\n",
    "\n",
    "run = wandb.init(\n",
    "    project='garbage-classification',\n",
    "    name='simple-cnn',\n",
    "    config=CFG().__dict__\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "216781f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type                | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | model     | SimpleCNN           | 917 K  | train\n",
      "1 | criterion | CrossEntropyLoss    | 0      | train\n",
      "2 | f1        | MulticlassF1Score   | 0      | train\n",
      "3 | recall    | MulticlassRecall    | 0      | train\n",
      "4 | precision | MulticlassPrecision | 0      | train\n",
      "----------------------------------------------------------\n",
      "917 K     Trainable params\n",
      "0         Non-trainable params\n",
      "917 K     Total params\n",
      "3.671     Total estimated model params size (MB)\n",
      "26        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a702e1c120b4f5487499b6ff5c86860",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nevrohelios/miniconda3/envs/flsplit/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (38) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a8e9861705a446693f1ebbf0d560e72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0512684b5da414eb90f76e34f55c544",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3974f1063b96456b90631e1f5896c827",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a411f73af4f74f2e8c7333884dbbdd26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "127a64dad72b48db8baed47f875cd488",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da76b585e55a4a548b9141883f9f0083",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8619417c479f4b3bb0d6d037425cad75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f468aa82fc7d4d8482c5cd3269c497e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cefde29951c400b948bc1730eeb0593",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "992fe5b2dfa243f9af2d78c6db1bafe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b26687ade22c4c40b5f0498cb80e0a97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "model = SimpleCNN(\n",
    "    num_layers=CFG.num_layers,\n",
    "    filter_size=CFG.filter_size,\n",
    "    num_dense=CFG.num_dense,\n",
    "    conv_activation=CFG.conv_activation,\n",
    "    dense_activation=CFG.dense_activation,\n",
    "    in_channels=CFG.in_channels,\n",
    "    num_classes=CFG.num_classes,\n",
    "    stride=CFG.stride,\n",
    "    input_size=CFG.input_size\n",
    ")\n",
    "\n",
    "pl_model = ModelLightning(\n",
    "    model=model,\n",
    "    idx_to_class=idx_to_class,\n",
    "    run=run,\n",
    "    lr=CFG.lr\n",
    ")\n",
    "\n",
    "dm = DataLoaderWrapper(\n",
    "    train_dataset=train_dataset,\n",
    "    test_dataset=test_dataset,\n",
    "    batch_size=CFG.batch_size,\n",
    "    num_workers=CFG.num_workers\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=CFG.max_epochs,\n",
    "    accelerator='auto',\n",
    "    devices='auto'\n",
    ")\n",
    "\n",
    "trainer.fit(pl_model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61c14e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flsplit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
